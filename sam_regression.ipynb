{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f91Zqmwdm7pw"
   },
   "outputs": [],
   "source": [
    "# For Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Train.csv\")\n",
    "finaltest = pd.read_csv(\"Test.csv\")\n",
    "riders = pd.read_csv('Riders.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Order No       User Id Vehicle Type  Platform Type  \\\n0   Order_No_4211   User_Id_633         Bike              3   \n1  Order_No_25375  User_Id_2285         Bike              3   \n\n  Personal or Business  Placement - Day of Month  \\\n0             Business                         9   \n1             Personal                        12   \n\n   Placement - Weekday (Mo = 1) Placement - Time  Confirmation - Day of Month  \\\n0                             5       9:35:46 AM                            9   \n1                             5      11:16:16 AM                           12   \n\n   Confirmation - Weekday (Mo = 1)  ... Arrival at Destination - Time  \\\n0                                5  ...                   10:39:55 AM   \n1                                5  ...                   12:17:22 PM   \n\n   Distance (KM)  Temperature Precipitation in millimeters  Pickup Lat  \\\n0              4         20.4                          NaN   -1.317755   \n1             16         26.4                          NaN   -1.351453   \n\n   Pickup Long Destination Lat  Destination Long      Rider Id  \\\n0    36.830370       -1.300406         36.829741  Rider_Id_432   \n1    36.899315       -1.295004         36.814358  Rider_Id_856   \n\n  Time from Pickup to Arrival  \n0                         745  \n1                        1993  \n\n[2 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order No</th>\n      <th>User Id</th>\n      <th>Vehicle Type</th>\n      <th>Platform Type</th>\n      <th>Personal or Business</th>\n      <th>Placement - Day of Month</th>\n      <th>Placement - Weekday (Mo = 1)</th>\n      <th>Placement - Time</th>\n      <th>Confirmation - Day of Month</th>\n      <th>Confirmation - Weekday (Mo = 1)</th>\n      <th>...</th>\n      <th>Arrival at Destination - Time</th>\n      <th>Distance (KM)</th>\n      <th>Temperature</th>\n      <th>Precipitation in millimeters</th>\n      <th>Pickup Lat</th>\n      <th>Pickup Long</th>\n      <th>Destination Lat</th>\n      <th>Destination Long</th>\n      <th>Rider Id</th>\n      <th>Time from Pickup to Arrival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Order_No_4211</td>\n      <td>User_Id_633</td>\n      <td>Bike</td>\n      <td>3</td>\n      <td>Business</td>\n      <td>9</td>\n      <td>5</td>\n      <td>9:35:46 AM</td>\n      <td>9</td>\n      <td>5</td>\n      <td>...</td>\n      <td>10:39:55 AM</td>\n      <td>4</td>\n      <td>20.4</td>\n      <td>NaN</td>\n      <td>-1.317755</td>\n      <td>36.830370</td>\n      <td>-1.300406</td>\n      <td>36.829741</td>\n      <td>Rider_Id_432</td>\n      <td>745</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Order_No_25375</td>\n      <td>User_Id_2285</td>\n      <td>Bike</td>\n      <td>3</td>\n      <td>Personal</td>\n      <td>12</td>\n      <td>5</td>\n      <td>11:16:16 AM</td>\n      <td>12</td>\n      <td>5</td>\n      <td>...</td>\n      <td>12:17:22 PM</td>\n      <td>16</td>\n      <td>26.4</td>\n      <td>NaN</td>\n      <td>-1.351453</td>\n      <td>36.899315</td>\n      <td>-1.295004</td>\n      <td>36.814358</td>\n      <td>Rider_Id_856</td>\n      <td>1993</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Rider Id  No_Of_Orders   Age  Average_Rating  No_of_Ratings\n0  Rider_Id_396          2946  2298            14.0           1159\n1  Rider_Id_479           360   951            13.5            176",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rider Id</th>\n      <th>No_Of_Orders</th>\n      <th>Age</th>\n      <th>Average_Rating</th>\n      <th>No_of_Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rider_Id_396</td>\n      <td>2946</td>\n      <td>2298</td>\n      <td>14.0</td>\n      <td>1159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rider_Id_479</td>\n      <td>360</td>\n      <td>951</td>\n      <td>13.5</td>\n      <td>176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "riders.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Order No       User Id Vehicle Type  Platform Type  \\\n0  Order_No_19248  User_Id_3355         Bike              3   \n1  Order_No_12736  User_Id_3647         Bike              3   \n\n  Personal or Business  Placement - Day of Month  \\\n0             Business                        27   \n1             Business                        17   \n\n   Placement - Weekday (Mo = 1) Placement - Time  Confirmation - Day of Month  \\\n0                             3       4:44:10 PM                           27   \n1                             5      12:57:35 PM                           17   \n\n   Confirmation - Weekday (Mo = 1)  ... Pickup - Weekday (Mo = 1)  \\\n0                                3  ...                         3   \n1                                5  ...                         5   \n\n   Pickup - Time  Distance (KM) Temperature  Precipitation in millimeters  \\\n0     5:06:47 PM              8         NaN                           NaN   \n1     1:25:37 PM              5         NaN                           NaN   \n\n   Pickup Lat Pickup Long  Destination Lat  Destination Long      Rider Id  \n0   -1.333275   36.870815        -1.305249         36.822390  Rider_Id_192  \n1   -1.272639   36.794723        -1.277007         36.823907  Rider_Id_868  \n\n[2 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order No</th>\n      <th>User Id</th>\n      <th>Vehicle Type</th>\n      <th>Platform Type</th>\n      <th>Personal or Business</th>\n      <th>Placement - Day of Month</th>\n      <th>Placement - Weekday (Mo = 1)</th>\n      <th>Placement - Time</th>\n      <th>Confirmation - Day of Month</th>\n      <th>Confirmation - Weekday (Mo = 1)</th>\n      <th>...</th>\n      <th>Pickup - Weekday (Mo = 1)</th>\n      <th>Pickup - Time</th>\n      <th>Distance (KM)</th>\n      <th>Temperature</th>\n      <th>Precipitation in millimeters</th>\n      <th>Pickup Lat</th>\n      <th>Pickup Long</th>\n      <th>Destination Lat</th>\n      <th>Destination Long</th>\n      <th>Rider Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Order_No_19248</td>\n      <td>User_Id_3355</td>\n      <td>Bike</td>\n      <td>3</td>\n      <td>Business</td>\n      <td>27</td>\n      <td>3</td>\n      <td>4:44:10 PM</td>\n      <td>27</td>\n      <td>3</td>\n      <td>...</td>\n      <td>3</td>\n      <td>5:06:47 PM</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.333275</td>\n      <td>36.870815</td>\n      <td>-1.305249</td>\n      <td>36.822390</td>\n      <td>Rider_Id_192</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Order_No_12736</td>\n      <td>User_Id_3647</td>\n      <td>Bike</td>\n      <td>3</td>\n      <td>Business</td>\n      <td>17</td>\n      <td>5</td>\n      <td>12:57:35 PM</td>\n      <td>17</td>\n      <td>5</td>\n      <td>...</td>\n      <td>5</td>\n      <td>1:25:37 PM</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.272639</td>\n      <td>36.794723</td>\n      <td>-1.277007</td>\n      <td>36.823907</td>\n      <td>Rider_Id_868</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "finaltest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Arrival at Destination - Day of Month',\n 'Arrival at Destination - Time',\n 'Arrival at Destination - Weekday (Mo = 1)',\n 'Time from Pickup to Arrival'}"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "set(dataset.columns) - set(finaltest.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we must drop the above before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are the columns in the final that are not on training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "set()"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "set(finaltest.columns) - set(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = dataset.drop(columns=['Time from Pickup to Arrival', 'User Id', 'Order No', \n",
    "'Arrival at Destination - Day of Month',\n",
    "'Arrival at Destination - Time',\n",
    "'Arrival at Destination - Weekday (Mo = 1)'])\n",
    "X = xdata.copy() # I want to run this column everytime I want to restart after changes\n",
    "X = X.merge(riders, how='left', on=['Rider Id']).drop(columns=['Rider Id'])\n",
    "\n",
    "f_testx = finaltest.merge(riders, how='left', on=['Rider Id']).drop(columns=['User Id', 'Order No', 'Rider Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Time from Pickup to Arrival'] # The target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm columns if columns on train are those on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "set(f_testx.columns) == set(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now things are about to get ugly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def cleaner(input_df, nullthreshold=0.9, correlation_thresh=0.95, day_of_month_cols=[], day_of_week_cols=[]):\n",
    "    input_dfc = input_df.copy()\n",
    "    \n",
    "\n",
    "    #########################################################################################\n",
    "    # The Code below drops columns that have null values exceeding threshold and Columns that have ONLY one value\n",
    "    for col in input_df.columns:\n",
    "        if (sum(input_df[col].isnull())/len(input_df[col]) > nullthreshold) or (len(input_df[col].unique()) == 1):\n",
    "            input_dfc.drop(columns=[col], inplace=True) \n",
    "            \n",
    "    #########################################################################################\n",
    "\n",
    "    #########################################################################################\n",
    "    #This code converts time given by am and pm into seconds then applies cosine and sine\n",
    "    def time_to_seconds(input_df):\n",
    "        input_dfc = input_df.copy()\n",
    "\n",
    "        from datetime import datetime\n",
    "\n",
    "        for time_col in [col for col in input_df.columns if 'Time' in [col[-4:]]]:\n",
    "\n",
    "            input_dfc[time_col + '_sin(seconds)'] = \\\n",
    "            input_df[time_col].apply(lambda time: np.sin(\n",
    "                (datetime.strptime(time, '%I:%M:%S %p') - datetime(1900,1,1)).total_seconds() \\\n",
    "                * (2.*np.pi/86400) )) # there are 86400 seconds in a day\n",
    "\n",
    "            input_dfc[time_col + '_cos(seconds)'] = \\\n",
    "            input_df[time_col].apply(lambda time: np.cos(\n",
    "                (datetime.strptime(time, '%I:%M:%S %p') - datetime(1900,1,1)).total_seconds() \\\n",
    "                * (2.*np.pi/86400) ))\n",
    "\n",
    "            input_dfc.drop(columns=[time_col], inplace=True)\n",
    "\n",
    "        return input_dfc\n",
    "\n",
    "    input_dfc2 = time_to_seconds(input_dfc)\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    # This code encodes ['Platform Type', 'Personal or Business']\n",
    "    \n",
    "    def one_encoder(input_df, columns):\n",
    "    \n",
    "        return pd.get_dummies(input_df, drop_first=True, columns=columns, dtype=float)\n",
    "\n",
    "    \n",
    "    input_dfc2 = one_encoder(input_dfc2, ['Platform Type', 'Personal or Business'])\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    # This code will remove one of a pair of variables that are 95% correlated\n",
    "    def correlation_drop(df, thresh):\n",
    "        while True:\n",
    "            corr_matrix = df.corr(method = \"spearman\").abs()\n",
    "            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "            to_drop = [column for column in upper.columns if any(upper[column] > thresh)]\n",
    "            if len(to_drop) == 0:\n",
    "                break\n",
    "            else:\n",
    "                df = df.drop(to_drop, axis = 1)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    input_dfc2 = correlation_drop(input_dfc2, correlation_thresh)\n",
    "    #########################################################################################\n",
    "\n",
    "    print(f\"Total of {len([x for x in input_df.columns if x not in input_dfc2])} original columns dropped \\n\")  \n",
    "    print(f\"Total of {len([x for x in input_dfc2.columns if x not in input_df])} new CLEAN columns formed \\n\")\n",
    "    print(f\"Dataframe now has {len(input_dfc2.columns)} from {len(input_df.columns)} input columns\")\n",
    "    #print([x for x in input_df.columns if x not in input_dfc2])\n",
    "\n",
    "    return input_dfc2\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Placement - Day of Month  Placement - Weekday (Mo = 1)  Distance (KM)  \\\n0                         9                             5              4   \n1                        12                             5             16   \n2                        30                             2              3   \n3                        15                             5              9   \n4                        13                             1              9   \n\n   Temperature  Pickup Lat  Pickup Long  Destination Lat  Destination Long  \\\n0         20.4   -1.317755    36.830370        -1.300406         36.829741   \n1         26.4   -1.351453    36.899315        -1.295004         36.814358   \n2          NaN   -1.308284    36.843419        -1.300921         36.828195   \n3         19.2   -1.281301    36.832396        -1.257147         36.795063   \n4         15.4   -1.266597    36.792118        -1.295041         36.809817   \n\n   No_Of_Orders   Age  Average_Rating  No_of_Ratings  \\\n0          1637  1309            13.8            549   \n1           396   339            13.6             69   \n2          1023   242            12.5            114   \n3           886   283            14.5            113   \n4          2311   872            14.1            533   \n\n   Placement - Time_sin(seconds)  Placement - Time_cos(seconds)  \\\n0                       0.588609                      -0.808418   \n1                       0.189667                      -0.981849   \n2                      -0.171141                      -0.985247   \n3                       0.623993                      -0.781430   \n4                       0.517654                      -0.855590   \n\n   Platform Type_2  Platform Type_3  Platform Type_4  \\\n0              0.0              1.0              0.0   \n1              0.0              1.0              0.0   \n2              0.0              1.0              0.0   \n3              0.0              1.0              0.0   \n4              0.0              0.0              0.0   \n\n   Personal or Business_Personal  \n0                            0.0  \n1                            1.0  \n2                            0.0  \n3                            0.0  \n4                            1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Placement - Day of Month</th>\n      <th>Placement - Weekday (Mo = 1)</th>\n      <th>Distance (KM)</th>\n      <th>Temperature</th>\n      <th>Pickup Lat</th>\n      <th>Pickup Long</th>\n      <th>Destination Lat</th>\n      <th>Destination Long</th>\n      <th>No_Of_Orders</th>\n      <th>Age</th>\n      <th>Average_Rating</th>\n      <th>No_of_Ratings</th>\n      <th>Placement - Time_sin(seconds)</th>\n      <th>Placement - Time_cos(seconds)</th>\n      <th>Platform Type_2</th>\n      <th>Platform Type_3</th>\n      <th>Platform Type_4</th>\n      <th>Personal or Business_Personal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>5</td>\n      <td>4</td>\n      <td>20.4</td>\n      <td>-1.317755</td>\n      <td>36.830370</td>\n      <td>-1.300406</td>\n      <td>36.829741</td>\n      <td>1637</td>\n      <td>1309</td>\n      <td>13.8</td>\n      <td>549</td>\n      <td>0.588609</td>\n      <td>-0.808418</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>5</td>\n      <td>16</td>\n      <td>26.4</td>\n      <td>-1.351453</td>\n      <td>36.899315</td>\n      <td>-1.295004</td>\n      <td>36.814358</td>\n      <td>396</td>\n      <td>339</td>\n      <td>13.6</td>\n      <td>69</td>\n      <td>0.189667</td>\n      <td>-0.981849</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>2</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>-1.308284</td>\n      <td>36.843419</td>\n      <td>-1.300921</td>\n      <td>36.828195</td>\n      <td>1023</td>\n      <td>242</td>\n      <td>12.5</td>\n      <td>114</td>\n      <td>-0.171141</td>\n      <td>-0.985247</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>5</td>\n      <td>9</td>\n      <td>19.2</td>\n      <td>-1.281301</td>\n      <td>36.832396</td>\n      <td>-1.257147</td>\n      <td>36.795063</td>\n      <td>886</td>\n      <td>283</td>\n      <td>14.5</td>\n      <td>113</td>\n      <td>0.623993</td>\n      <td>-0.781430</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>1</td>\n      <td>9</td>\n      <td>15.4</td>\n      <td>-1.266597</td>\n      <td>36.792118</td>\n      <td>-1.295041</td>\n      <td>36.809817</td>\n      <td>2311</td>\n      <td>872</td>\n      <td>14.1</td>\n      <td>533</td>\n      <td>0.517654</td>\n      <td>-0.855590</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply our ultimate cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Platform Type', 'Personal or Business'], dtype='object')] are in the [columns]\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-163403658570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mday_of_month_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Month'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mday_of_week_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(Mo = 1)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'(Mo = 1)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_of_month_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday_of_month_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_of_week_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday_of_week_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-a922f42951bf>\u001b[0m in \u001b[0;36mcleaner\u001b[1;34m(input_df, nullthreshold, correlation_thresh, day_of_month_cols, day_of_week_cols)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0minput_dfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dfc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Platform Type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Personal or Business'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m#########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-a922f42951bf>\u001b[0m in \u001b[0;36mone_encoder\u001b[1;34m(input_df, columns)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Platform Type', 'Personal or Business'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "day_of_month_cols = [x for x in X.columns if x[-5:] == 'Month']\n",
    "day_of_week_cols = [x for x in X.columns if x[-(len('(Mo = 1)')):] == '(Mo = 1)']\n",
    "X_train = cleaner(X_train, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Platform Type', 'Personal or Business'], dtype='object')] are in the [columns]\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-b0f9f5b15c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_of_month_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday_of_month_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_of_week_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday_of_week_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-95-a922f42951bf>\u001b[0m in \u001b[0;36mcleaner\u001b[1;34m(input_df, nullthreshold, correlation_thresh, day_of_month_cols, day_of_week_cols)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0minput_dfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dfc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Platform Type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Personal or Business'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m#########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-a922f42951bf>\u001b[0m in \u001b[0;36mone_encoder\u001b[1;34m(input_df, columns)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Platform Type', 'Personal or Business'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "X_test = cleaner(X_test, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total of 14 original columns dropped \n\nTotal of 6 new CLEAN columns formed \n\nDataframe now has 18 from 26 input columns\n"
    }
   ],
   "source": [
    "X1 = cleaner(X, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols) # When we want to create a cross validation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also apply it on our finial test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total of 14 original columns dropped \n\nTotal of 6 new CLEAN columns formed \n\nDataframe now has 18 from 26 input columns\n"
    }
   ],
   "source": [
    "F_test = cleaner(f_testx, day_of_month_cols=day_of_month_cols, day_of_week_cols=day_of_week_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = X_train.corr(method = \"spearman\").abs()\n",
    "# sns.set(font_scale = 1.0)\n",
    "# f, ax = plt.subplots(figsize=(11, 9))\n",
    "# sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "# f.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will standardize the columns which have a max absolute value that is greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'We use this code to apply standard scaler, and still keep our data as a dataframe instead of an array'\n",
    "\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# mapper = DataFrameMapper([(X_train.columns, StandardScaler())])\n",
    "# scaled_features = mapper.fit_transform(X_train.copy(), 4)\n",
    "# scaled_features_df = pd.DataFrame(scaled_features, index=X_train.index, columns=X_train.columns)\n",
    "# scaled_features_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Placement - Day of Month  Placement - Weekday (Mo = 1)  Distance (KM)  \\\n19798                         7                             4             16   \n9959                         28                             5             10   \n\n       Temperature  Pickup Lat  Pickup Long  Destination Lat  \\\n19798         16.8   -1.304033    36.784869        -1.229720   \n9959          25.7   -1.304524    36.775371        -1.255189   \n\n       Destination Long  No_Of_Orders  Age  Average_Rating  No_of_Ratings  \\\n19798         36.874551           721  984            13.8            161   \n9959          36.782203           532  740            14.0             44   \n\n       Placement - Time_sin(seconds)  Placement - Time_cos(seconds)  \\\n19798                      -0.194591                      -0.980884   \n9959                       -0.329210                      -0.944257   \n\n       Platform Type_2  Platform Type_3  Platform Type_4  \\\n19798              0.0              1.0              0.0   \n9959               0.0              0.0              0.0   \n\n       Personal or Business_Personal  \n19798                            0.0  \n9959                             0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Placement - Day of Month</th>\n      <th>Placement - Weekday (Mo = 1)</th>\n      <th>Distance (KM)</th>\n      <th>Temperature</th>\n      <th>Pickup Lat</th>\n      <th>Pickup Long</th>\n      <th>Destination Lat</th>\n      <th>Destination Long</th>\n      <th>No_Of_Orders</th>\n      <th>Age</th>\n      <th>Average_Rating</th>\n      <th>No_of_Ratings</th>\n      <th>Placement - Time_sin(seconds)</th>\n      <th>Placement - Time_cos(seconds)</th>\n      <th>Platform Type_2</th>\n      <th>Platform Type_3</th>\n      <th>Platform Type_4</th>\n      <th>Personal or Business_Personal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19798</th>\n      <td>7</td>\n      <td>4</td>\n      <td>16</td>\n      <td>16.8</td>\n      <td>-1.304033</td>\n      <td>36.784869</td>\n      <td>-1.229720</td>\n      <td>36.874551</td>\n      <td>721</td>\n      <td>984</td>\n      <td>13.8</td>\n      <td>161</td>\n      <td>-0.194591</td>\n      <td>-0.980884</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9959</th>\n      <td>28</td>\n      <td>5</td>\n      <td>10</td>\n      <td>25.7</td>\n      <td>-1.304524</td>\n      <td>36.775371</td>\n      <td>-1.255189</td>\n      <td>36.782203</td>\n      <td>532</td>\n      <td>740</td>\n      <td>14.0</td>\n      <td>44</td>\n      <td>-0.329210</td>\n      <td>-0.944257</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CV Scoring Result: mean= 796.969038169289 std= 34500.51937564535\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "polinomial_features = PolynomialFeatures(1)\n",
    "# Construct the pipeline with a standard scaler and a small neural network\n",
    "estimators = []\n",
    "estimators.append(('imputer', SimpleImputer(strategy='median')))\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('plf', polinomial_features))\n",
    "estimators.append(('mod', Lasso(alpha=0.01)))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# To begin, let's use only these two features to predict 'cnt' (bicycle count)\n",
    "\n",
    "\n",
    "# We'll use 5-fold cross validation. That is, a random 80% of the data will be used\n",
    "# to train the model, and the prediction score will be computed on the remaining 20%.\n",
    "# This process is repeated five times such that the training sets in each \"fold\"\n",
    "# are mutually orthogonal.\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "results = cross_val_score(model, X1, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "print ('CV Scoring Result: mean=',np.sqrt(abs(np.mean(results))),'std=',np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('imputer',\n  SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n                missing_values=nan, strategy='median', verbose=0)),\n ('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)),\n ('plf',\n  PolynomialFeatures(degree=1, include_bias=True, interaction_only=False,\n                     order='C')),\n ('mod',\n  Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n        normalize=False, positive=False, precompute=False, random_state=None,\n        selection='cyclic', tol=0.0001, warm_start=False))]"
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix = scaled_features_df.corr(method = \"spearman\").abs()\n",
    "# sns.set(font_scale = 1.0)\n",
    "# f, ax = plt.subplots(figsize=(11, 9))\n",
    "# sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "# f.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs.fit(scaled_features_df, y_train)\n",
    "# sfs.k_feature_names_ \n",
    "# don't mind this code\n",
    "# sfs.scorer(LinearRegression(), scaled_features_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\nmodel r2 score: 0.355\nmodel rmse score: 786.4034935748099\n\n\n"
    }
   ],
   "source": [
    "models = [LinearRegression()]\n",
    "polinomial_features = PolynomialFeatures(2)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    # numeric_transformer = Pipeline(steps=[\n",
    "    # ('imputer', SimpleImputer(strategy='median')),\n",
    "    # ('scaler', StandardScaler())])\n",
    "    \n",
    "    # preprocessor = ColumnTransformer(\n",
    "    # transformers=[\n",
    "    #     ('num', numeric_transformer, cols_to_standard)])\n",
    "    \n",
    "    steps = [('imputer', SimpleImputer(strategy='mean')), ('polf', polinomial_features), \n",
    "          ('Scaler', StandardScaler()),\n",
    "          ('model', model)]\n",
    "    \n",
    "    pipe = Pipeline(steps)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(model)\n",
    "    print(\"model r2 score: %.3f\" % pipe.score(X_test, y_test))\n",
    "    print(f\"model rmse score: {np.sqrt(mean_squared_error(y_test, y_pred))}\")\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "mean_squared_error() got an unexpected keyword argument 'squared'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-e4feee0604fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: mean_squared_error() got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('SampleSubmission.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMuW28rZFUbkQlqjGk0nZFk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "sam_regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}